
import streamlit as st
import pandas as pd
from difflib import SequenceMatcher

st.set_page_config(page_title="Institutional Menu Checker", layout="wide")
st.title("ğŸ“„ Institutional Lunch Menu Checker")

st.markdown("""Upload a **menu file** (Excel) and a **rules file** with frequency and keyword conditions.
The system will highlight frequency violations based on your definitions, including customized matching rules (e.g., 'chicken wings', 'stuffed chicken', 'tabit').""")

menu_file = st.file_uploader("Upload Menu Excel File", type="xlsx", key="menu")
rules_file = st.file_uploader("Upload Rules Excel File", type="xlsx", key="rules")

if menu_file and rules_file:
    with st.spinner("Processing data..."):
        menu_xls = pd.ExcelFile(menu_file)
        rules_xls = pd.ExcelFile(rules_file)

        min_freq_df = rules_xls.parse("×ª×“×™×¨×•×ª ××™× ×™××œ×™×ª")
        min_freq_df.columns = min_freq_df.iloc[0]
        min_freq_df = min_freq_df.drop([0, 1, 2]).dropna(subset=["×¡×•×’"])

        all_weeks_df = pd.DataFrame()
        for sheet in menu_xls.sheet_names:
            df = menu_xls.parse(sheet)
            df.columns = df.iloc[1]
            df = df.drop([0, 1])
            all_weeks_df = pd.concat([all_weeks_df, df], ignore_index=True)

        day_cols = [c for c in all_weeks_df.columns if "×™×•×" in str(c)]
        for col in day_cols:
            all_weeks_df[col] = all_weeks_df[col].astype(str).str.replace("âŒ", "").str.strip()

        actual_dishes = pd.Series(all_weeks_df[day_cols].values.ravel()).dropna().str.strip().str.lower()

        def fuzzy_match(k, dish):
            return SequenceMatcher(None, k, dish).ratio() >= 0.85

        def get_keywords(row):
            keywords = set()
            for col in ["××œ×œ ×—×œ×•×¤×™", "×™×›×•×œ ×œ×”×•×¤×™×¢ ×›", "×“×•×’×××•×ª ××”×ª×¤×¨×™×˜"]:
                if pd.notna(row.get(col)):
                    keywords.update(x.strip().lower() for x in str(row[col]).split("/"))
            keywords.add(str(row["×¡×•×’"]).strip().lower())
            return list(keywords)

        # ×›×œ×œ×™× ××•×ª×××™× ××™×©×™×ª ×œ×¤×™ ××™×©×•×¨ ×”××©×ª××©
        custom_equivalents = {
            "×©×™×¤×•×“×™ ×›× ×¤×™×™× ×¢× ×™×¨×§×•×ª ×’×¨×™×œ": ["×›× ×¤×™×™×"],
            "×¢×•×¤×•×ª ×©×œ××™× ×‘×’×¨×™×œ": ["×¢×•×£ ×©×œ×", "×¢×•×¤×•×ª ×©×œ××™×"],
            "×˜×‘×™×ª ×¢×•×¤×•×ª ×¦×œ×•×™×™× ×¢× ××•×¨×– ×•×‘×”×¨×˜": ["×˜×‘×™×ª"],
            "×¡×œ×˜ ××‘×•×§×“×•": ["××‘×•×§×“×•"],
            "×¡×œ×˜ ×¤×˜×¨×™×•×ª ××¡×™×™×ª×™": ["×¤×˜×¨×™×•×ª ××¡×™×™×ª×™", "×¤×˜×¨×™×•×ª ××¡×™×™××ª×™"],
    "×©× ×™×¦×œ ×¢×•×£ ×¤×¨×™×š": ["×©× ×™×¦×œ"],
    "×—×–×” ×¢×•×£ ×‘×’×¨×™×œ": ["×—×–×” ×¢×•×£"],
    "×”××‘×•×¨×’×¨ ×‘×§×¨": ["×”××‘×•×¨×’×¨"],
    "×§×¦×™×¦×•×ª ×‘×§×¨ ×‘×¨×•×˜×‘": ["×§×¦×™×¦×•×ª ×‘×©×¨ ×‘×¨×•×˜×‘ ××“×•× ×¢×œ ×§×•×¡×§×•×¡", "×§×¦×™×¦×•×ª ×‘×¨×•×˜×‘ ××“×•× ×¤×™×§× ×˜×™×™"],
    "×‘×§×œ×•×•××ª ×‘×©×¨": ["×‘×§×œ××•×•×ª ×‘×©×¨ ××“×¤×™ ×¤×™×œ×• ×‘×¡×’× ×•×Ÿ ×¡×•×›×¨×™×”"],
    "×××•×œ××™× ×§×˜× ×™×": [
        "×¤×¨×’×™×ª ×××•×œ××ª ××•×¨×– ×œ×¦×“ ×™×¨×§×•×ª ×¦×œ×•×™×™×",
        "×¤×™×œ×” ×¤×™×œ×• ×××•×œ× ×‘×ª×¢×¨×•×‘×ª ×‘×©×¨ ×¢×’×œ",
        "×—×¦×™×œ ×××•×œ×",
        "×¢×œ×™ ×’×¤×Ÿ ×××•×œ××™×"
    ],
        }

        def count_matches(keywords, series, original_name):
            count = 0
            for dish in series:
                dish = dish.strip().lower()

                # ×”×ª×××” ×œ×¤×™ ×›×œ×œ ××•×ª×× ××™×©×™
                for rule_name, rule_keywords in custom_equivalents.items():
                if any(trigger in name for trigger in [rule_name]) or any(trigger in name for trigger in rule_keywords):
                    if any(custom_kw in dish for custom_kw in rule_keywords):
                        count += 1
                        break

                    if any(custom_kw in dish for custom_kw in custom_equivalents[original_name]):
                        count += 1
                        continue

                # ×”×ª×××” ××œ××”
                if dish in keywords:
                    count += 1
                    continue

                # ×”×ª×××” ×œ×¤×™ ×œ×¤×—×•×ª ×©×ª×™ ××™×œ×™× ××ª×•×š ×”×¨×©×™××”
                if sum(1 for k in keywords if k in dish) >= 2:
                    count += 1
                    continue

                # ××™×œ×” ××—×ª ××ª×•×š ×”×¨×©×™××”
                if len(keywords) == 1 and any(k in dish for k in keywords):
                    count += 1
                    continue

                # ×”×ª×××” fuzzy
                if any(fuzzy_match(k, dish) for k in keywords):
                    count += 1
            return count

        report = []
        for _, row in min_freq_df.iterrows():
            name = str(row["×¡×•×’"]).strip()
            keywords = get_keywords(row)
            required = row.get("×‘×—×•×“×©") or row.get("×‘×©×‘×•×¢")
            try:
                required = int(required) if row.get("×‘×—×•×“×©") else int(required) * 5
            except:
                continue
            actual = count_matches(keywords, actual_dishes, name)
            if actual < required:
                report.append({
                    "Dish Type": name,
                    "Required": required,
                    "Actual Found": actual,
                    "Gap": required - actual
                })

        result_df = pd.DataFrame(report)

    st.success("Menu check completed.")
    st.dataframe(result_df, use_container_width=True)
    st.download_button("Download CSV Report", result_df.to_csv(index=False).encode("utf-8"), file_name="menu_report.csv")
